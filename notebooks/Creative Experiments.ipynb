{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Setup-Super-Resolution\" data-toc-modified-id=\"Setup-Super-Resolution-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setup Super-Resolution</a></span></li><li><span><a href=\"#Cyclical-Feeding\" data-toc-modified-id=\"Cyclical-Feeding-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cyclical Feeding</a></span><ul class=\"toc-item\"><li><span><a href=\"#TODOs\" data-toc-modified-id=\"TODOs-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>TODOs</a></span></li></ul></li><li><span><a href=\"#Image-Sharpening\" data-toc-modified-id=\"Image-Sharpening-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Image Sharpening</a></span></li><li><span><a href=\"#Source-Data-FaceSwap-and-Upscaling\" data-toc-modified-id=\"Source-Data-FaceSwap-and-Upscaling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Source Data FaceSwap and Upscaling</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Notebook exploring random experiments around the use of the trained Faceswap generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "sys.path.append('../face_swap')\n",
    "\n",
    "from utils import image_processing\n",
    "\n",
    "from face_swap import faceswap_utils as utils\n",
    "from face_swap import FaceGenerator, FaceDetector\n",
    "from face_swap import gan, gan_utils\n",
    "from face_swap import CONFIG_PATH\n",
    "from face_swap.Face import Face\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = Path.home() / \"Documents/datasets/\"\n",
    "models_folder = Path.home() / \"Documents/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(str(data_folder / \"cifar-10-batches-py\" / \"data_batch_1\"), 'rb') as fo:\n",
    "    cifar = pickle.load(fo, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_img = np.rollaxis(cifar[b'data'][3].reshape(3, 32, 32), 0, 3)\n",
    "cifar_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(data_folder / \"cat-pet-animal-domestic-104827.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cifar_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load two random celeba faces\n",
    "from_face_img = cv2.cvtColor(cv2.imread(str(data_folder / \"img_align_celeba\" / \n",
    "                            \"000{}{}{}.jpg\".format(*np.random.randint(0, 9, 3)))),\n",
    "                             cv2.COLOR_BGR2RGB)\n",
    "to_face_img = cv2.cvtColor(cv2.imread(str(data_folder / \"img_align_celeba\" / \n",
    "                          \"000{}{}{}.jpg\".format(*np.random.randint(0, 9, 3)))),\n",
    "                       cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(from_face_img)\n",
    "plt.show()\n",
    "plt.imshow(to_face_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Super-Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import super_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'models_path' : str(models_folder / \"super_resolution/v1\"),\n",
    "    'LR_IMG_SHAPE' : \"(64, 64, 3)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_model = super_resolution.get_SRResNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hr_version(sr_model, lr_img):\n",
    "    hr_image = sr_model.predict(np.asarray([lr_img/255.0]))[0]\n",
    "    hr_image = np.clip(hr_image * 255, 0, 255).astype(np.uint8)\n",
    "    return hr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclical Feeding\n",
    "Cycling feeding own output to generator. Can start with actual face or random noise. \n",
    "\n",
    "## TODOs\n",
    "* Try apply text on image before feeding to generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zoom(img, zoom_factor=1.2):\n",
    "    h, w = img.shape[:2]\n",
    "    mat = cv2.getRotationMatrix2D((w, h), 0, zoom_factor)\n",
    "    mat[:, 2] += (h//2, w//2)\n",
    "    result = cv2.warpAffine(img, mat, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "with open(CONFIG_PATH, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "model_cfg = cfg['masked_gan']['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generator and related functions\n",
    "gen_a, gen_b, _, _ = gan.get_gan(model_cfg, load_discriminators=False)\n",
    "_, _, _, fun_generate_a, fun_mask_a, fun_abgr_a = gan_utils.cycle_variables_masked(gen_a)\n",
    "_, _, _, fun_generate_b, fun_mask_b, fun_abgr_b = gan_utils.cycle_variables_masked(gen_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_fun_a = lambda x: fun_abgr_a([np.expand_dims(x, 0)])[0][0]\n",
    "gen_fun_b = lambda x: fun_abgr_b([np.expand_dims(x, 0)])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_a = FaceGenerator.FaceGenerator(\n",
    "            lambda face_img: FaceGenerator.gan_masked_generate_face(gen_fun_a, face_img),\n",
    "            input_size=(64, 64), tanh_fix=True)\n",
    "generator_b = FaceGenerator.FaceGenerator(\n",
    "            lambda face_img: FaceGenerator.gan_masked_generate_face(gen_fun_b, face_img),\n",
    "            input_size=(64, 64), tanh_fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = Face(img, img)\n",
    "use_a = True\n",
    "generator = generator_a if use_a else generator_b\n",
    "for i in range(500):\n",
    "    out = get_hr_version(sr_model, generator.generate(gen_input, (64, 64))[0])\n",
    "    #out = generator.generate(gen_input, (128, 128))[0]\n",
    "    gen_input.face_img = out\n",
    "    #gen_input.img = zoom(out)\n",
    "    res_path = str(data_folder / 'faceswap_experiments/cycle_feed/02/_{:04d}.png'.format(i))\n",
    "    cv2.imwrite(res_path, zoom(out))\n",
    "    cv2.imwrite(res_path, out)\n",
    "    # swap generator randomly every epoch\n",
    "    #generator = generator_a if np.random.rand() > 0.5 else generator_b\n",
    "    # swap generator every N epoch\n",
    "    #if i%10 == 0:\n",
    "    #    use_a = not use_a\n",
    "    #    generator = generator_a if use_a else generator_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://github.com/AdityaPokharel/Sharpen-Image\n",
    "regular_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "edge_enhance_kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "                               [-1,2,2,2,-1],\n",
    "                               [-1,2,8,2,-1],\n",
    "                               [-2,2,2,2,-1],\n",
    "                               [-1,-1,-1,-1,-1]])/8.0\n",
    "def sharpen(img, kernel=regular_kernel):\n",
    "    # apply kernel to input image\n",
    "    res = cv2.filter2D(img, -1, kernel)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(sharpen(to_face_img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Source Data FaceSwap and Upscaling\n",
    "Try to cherry pick some results of face-swapping on the training data, apply upscaling to a reasonable size (e.g. 128x128) and any possible post-processing that might help in improving image quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = data_folder / \"facesets/cage\"\n",
    "out_path = data_folder / \"faceswap_experiments/source_faceswap/cage_trump\"\n",
    "\n",
    "out_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected all image paths\n",
    "img_paths = image_processing.get_imgs_paths(input_path, as_str=False)\n",
    "\n",
    "# iterate over all collected image paths\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    gen_input = Face(img, img)\n",
    "    gen_face = generator_b.generate(gen_input)[0]\n",
    "    gen_face = sharpen(gen_face)\n",
    "    gen_face = cv2.resize(gen_face, out_size)\n",
    "    cv2.imwrite(str(out_path / \"out_{:04d}.jpg\".format(i)),\n",
    "                            gen_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-processing]",
   "language": "python",
   "name": "conda-env-image-processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
