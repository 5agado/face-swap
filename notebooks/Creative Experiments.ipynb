{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Setup-Super-Resolution\" data-toc-modified-id=\"Setup-Super-Resolution-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setup Super-Resolution</a></span></li><li><span><a href=\"#Cyclical-Feeding\" data-toc-modified-id=\"Cyclical-Feeding-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cyclical Feeding</a></span><ul class=\"toc-item\"><li><span><a href=\"#TODOs\" data-toc-modified-id=\"TODOs-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>TODOs</a></span></li></ul></li><li><span><a href=\"#Image-Sharpening\" data-toc-modified-id=\"Image-Sharpening-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Image Sharpening</a></span></li><li><span><a href=\"#Source-Data-FaceSwap-and-Upscaling\" data-toc-modified-id=\"Source-Data-FaceSwap-and-Upscaling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Source Data FaceSwap and Upscaling</a></span></li><li><span><a href=\"#Celeba-Test\" data-toc-modified-id=\"Celeba-Test-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Celeba Test</a></span></li><li><span><a href=\"#B/W-to-Color\" data-toc-modified-id=\"B/W-to-Color-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>B/W to Color</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Notebook exploring random experiments around the use of the trained Faceswap generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pickle\n",
    "import yaml\n",
    "from numpy.random import shuffle\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting\n",
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "sys.path.append('../face_swap')\n",
    "\n",
    "from utils import image_processing\n",
    "from utils import super_resolution\n",
    "\n",
    "from face_swap.deep_swap import swap_faces, Swapper\n",
    "from face_swap import faceswap_utils as utils\n",
    "from face_swap.plot_utils import stack_images\n",
    "from face_swap import FaceGenerator, FaceDetector\n",
    "from face_swap.train import get_original_data\n",
    "from face_swap import gan, gan_utils\n",
    "from face_swap import CONFIG_PATH\n",
    "from face_swap.Face import Face\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path.home() / \"Documents/datasets/\"\n",
    "models_folder = Path.home() / \"Documents/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two random celeba faces\n",
    "from_face_img = cv2.cvtColor(cv2.imread(str(data_folder / \"img_align_celeba\" / \n",
    "                            \"000{}{}{}.jpg\".format(*np.random.randint(0, 9, 3)))),\n",
    "                             cv2.COLOR_BGR2RGB)\n",
    "to_face_img = cv2.cvtColor(cv2.imread(str(data_folder / \"img_align_celeba\" / \n",
    "                          \"000{}{}{}.jpg\".format(*np.random.randint(0, 9, 3)))),\n",
    "                       cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(from_face_img)\n",
    "plt.show()\n",
    "plt.imshow(to_face_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclical Feeding\n",
    "Cycling feeding own output to generator. Can start with actual face or random noise. \n",
    "\n",
    "## TODOs\n",
    "* Try apply text on image before feeding to generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, crop_factor=0.2):\n",
    "    h, w = img.shape[:2]\n",
    "    h_crop = int((h * crop_factor)//2)\n",
    "    w_crop = int((w * crop_factor)//2)\n",
    "    return img[h_crop:h-h_crop, w_crop:w-w_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(img, zoom_factor=1.5):\n",
    "    h, w = img.shape[:2]\n",
    "    mat = cv2.getRotationMatrix2D((w//2, h//2), 0, zoom_factor)\n",
    "    #mat[:, 2] -= (w//2, h//2)\n",
    "    result = cv2.warpAffine(img, mat, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "with open(CONFIG_PATH, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "model_cfg = cfg['masked_gan']['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generator and related functions\n",
    "gen_a, gen_b, _, _ = gan.get_gan(model_cfg, load_discriminators=False)\n",
    "_, _, _, fun_generate_a, fun_mask_a, fun_abgr_a = gan_utils.cycle_variables_masked(gen_a)\n",
    "_, _, _, fun_generate_b, fun_mask_b, fun_abgr_b = gan_utils.cycle_variables_masked(gen_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fun_a = lambda x: fun_abgr_a([np.expand_dims(x, 0)])[0][0]\n",
    "gen_fun_b = lambda x: fun_abgr_b([np.expand_dims(x, 0)])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_a = FaceGenerator.FaceGenerator(\n",
    "            lambda face_img: FaceGenerator.gan_masked_generate_face(gen_fun_a, face_img),\n",
    "            input_size=(64, 64), tanh_fix=True)\n",
    "generator_b = FaceGenerator.FaceGenerator(\n",
    "            lambda face_img: FaceGenerator.gan_masked_generate_face(gen_fun_b, face_img),\n",
    "            input_size=(64, 64), tanh_fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = Face(img, img)\n",
    "use_a = True\n",
    "generator = generator_a if use_a else generator_b\n",
    "for i in range(500):\n",
    "    out = get_hr_version(sr_model, generator.generate(gen_input, (64, 64))[0])\n",
    "    #out = generator.generate(gen_input, (128, 128))[0]\n",
    "    gen_input.face_img = FaceGenerator.random_transform(out, **cfg['random_transform'])\n",
    "    #gen_input.img = zoom(out)\n",
    "    res_path = str(data_folder / 'faceswap_experiments/cycle_feed/02/_{:04d}.png'.format(i))\n",
    "    #cv2.imwrite(res_path, zoom(out))\n",
    "    cv2.imwrite(res_path, out)\n",
    "    # swap generator randomly every epoch\n",
    "    #generator = generator_a if np.random.rand() > 0.5 else generator_b\n",
    "    # swap generator every N epoch\n",
    "    if i%50 == 0:\n",
    "        use_a = not use_a\n",
    "        generator = generator_a if use_a else generator_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/AdityaPokharel/Sharpen-Image\n",
    "regular_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "edge_enhance_kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "                               [-1,2,2,2,-1],\n",
    "                               [-1,2,8,2,-1],\n",
    "                               [-2,2,2,2,-1],\n",
    "                               [-1,-1,-1,-1,-1]])/8.0\n",
    "def sharpen(img, kernel=regular_kernel):\n",
    "    # apply kernel to input image\n",
    "    res = cv2.filter2D(img, -1, kernel)\n",
    "    return res\n",
    "\n",
    "# see also cv2.detailEnhance(src, sigma_s=10, sigma_r=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sharpen(to_face_img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Source Data FaceSwap and Upscaling\n",
    "Try to cherry pick some results of face-swapping on the training data, apply upscaling to a reasonable size (e.g. 128x128) and any possible post-processing that might help in improving image quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = data_folder / \"facesets\" / \"cage\"\n",
    "out_path = data_folder / \"faceswap_experiments\" / \"source_faceswap\" / \"cage_trump\"\n",
    "\n",
    "out_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected all image paths\n",
    "img_paths = image_processing.get_imgs_paths(input_path, as_str=False)\n",
    "\n",
    "# iterate over all collected image paths\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    gen_input = Face(img, img)\n",
    "    gen_face = generator_b.generate(gen_input)[0]\n",
    "    gen_face = sharpen(gen_face)\n",
    "    gen_face = cv2.resize(gen_face, out_size)\n",
    "    cv2.imwrite(str(out_path / \"out_{:04d}.jpg\".format(i)),\n",
    "                            gen_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celeba Test\n",
    "Test Celeba training and generation of artworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(images: list, predict_fun,\n",
    "                tanh_fix=False, save_to: str=None, \n",
    "                nb_test_imgs=14, nb_columns=3, white_border=3):\n",
    "    # need number of images divisible by number of columns\n",
    "    nb_rows = nb_test_imgs//nb_columns\n",
    "    assert nb_test_imgs % nb_columns == 0\n",
    "    images = images[0:nb_test_imgs]\n",
    "\n",
    "    figure = np.stack([\n",
    "                        images,\n",
    "                        predict_fun(images),\n",
    "                        ], axis=1)\n",
    "    # we split images on two columns\n",
    "    figure = figure.reshape((nb_columns, nb_rows) + figure.shape[1:])\n",
    "    figure = stack_images(figure)\n",
    "    img_width = images[0].shape[1]\n",
    "    img_height = images[0].shape[0]\n",
    "    for i in range(1, nb_columns):\n",
    "        x = img_width*2*i\n",
    "        figure[:, x-white_border:x+white_border, :] = 255.0\n",
    "    for i in range(1, nb_rows):\n",
    "        y = img_height*i\n",
    "        figure[y-white_border:y+white_border, :, :] = 255.0\n",
    "\n",
    "    if save_to:\n",
    "        cv2.imwrite(save_to, figure)\n",
    "    else:\n",
    "        figure = cv2.cvtColor(figure, cv2.COLOR_BGR2RGB)\n",
    "        #plt.imshow(figure)\n",
    "        #plt.show()\n",
    "        display(Image.fromarray(figure))\n",
    "        # crashes in notebooks\n",
    "        #cv2.imshow('', figure)\n",
    "        #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "with open(CONFIG_PATH, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile)\n",
    "model_cfg = cfg['masked_gan']['v1']\n",
    "model_cfg['models_path'] = str(models_folder / \"face_recognition/deep_faceswap/masked_gan/cage_celeba/v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "face_detector = FaceDetector.FaceDetector(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generator and related functions\n",
    "netGA, netGB, _, _ = gan.get_gan(model_cfg, load_discriminators=False)\n",
    "\n",
    "# define generation and plotting function\n",
    "# depending if using masked gan model or not\n",
    "if model_cfg['masked']:\n",
    "  distorted_A, fake_A, mask_A, path_A, fun_mask_A, fun_abgr_A = gan_utils.cycle_variables_masked(netGA)\n",
    "  distorted_B, fake_B, mask_B, path_B, fun_mask_B, fun_abgr_B = gan_utils.cycle_variables_masked(netGB)\n",
    "  #gen_plot_a = lambda x: np.array(path_A([x])[0]) \n",
    "  #gen_plot_b = lambda x: np.array(path_B([x])[0])\n",
    "  gen_plot_a = lambda x: np.array(fun_abgr_A([x])[0][ :, :, :, 1:]) \n",
    "  gen_plot_b = lambda x: np.array(fun_abgr_B([x])[0][ :, :, :, 1:])\n",
    "  gen_plot_mask_a = lambda x: np.array(fun_mask_A([x])[0])*2-1\n",
    "  gen_plot_mask_b = lambda x: np.array(fun_mask_B([x])[0])*2-1\n",
    "else:\n",
    "  gen_plot_a = lambda x: netGA.predict(x)\n",
    "  gen_plot_b = lambda x: netGB.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_model = super_resolution.get_SRResNet(cfg['super_resolution'])\n",
    "resize_fun = lambda img, size: FaceGenerator.super_resolution_resizing(sr_model, img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fun_a = lambda x: fun_abgr_A([np.expand_dims(x, 0)])[0][0]\n",
    "gen_fun_b = lambda x: fun_abgr_B([np.expand_dims(x, 0)])[0][0]\n",
    "gen_input_size = literal_eval(model_cfg['img_shape'])[:2]\n",
    "face_generator = FaceGenerator.FaceGenerator(\n",
    "    lambda face_img: FaceGenerator.gan_masked_generate_face(gen_fun_a, face_img),\n",
    "    input_size=gen_input_size, config=cfg['swap'], resize_fun=resize_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapper = Swapper(face_detector, face_generator, cfg['swap'], save_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(img):\n",
    "    face = Face(img.copy(), Face.Rectangle(0, 64, 64, 0))\n",
    "    #return swap_faces(face, face_detector, cfg['swap'], face_generator)\n",
    "    return face.get_face_img()\n",
    "#gen_plot_b = lambda x: [swap(img) for img in x]\n",
    "gen_plot = lambda x: [swapper.swap(img) for img in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_a = data_folder / 'facesets/cage'\n",
    "img_dir_b = data_folder / 'celeba_tmp'\n",
    "#images_a, images_b = get_original_data(img_dir_a, img_dir_b, img_size=None, tanh_fix=False)\n",
    "images = image_processing.load_data(image_processing.get_imgs_paths(img_dir_a), (128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = str(data_folder / \"faceswap_experiments/source_faceswap/cage_celeba_masked/test_1/_{}.png\")\n",
    "swapper.config['mask_method'] = \"gen_mask\"\n",
    "face_generator.border_expand = (0.1, 0.1)\n",
    "face_generator.blur_size = 13\n",
    "face_generator.align = False\n",
    "#shuffle(images)\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    images_subset = images[i*15:(i+1)*15]\n",
    "    try:\n",
    "        plot_sample(images_subset, gen_plot, nb_test_imgs=15, nb_columns=3, \n",
    "                    save_to=dest_folder.format(i), tanh_fix=False)\n",
    "    except FaceDetector.FaceSwapException:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-processing]",
   "language": "python",
   "name": "conda-env-image-processing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
